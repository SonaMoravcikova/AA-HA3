{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f97889-6efb-45fd-bde3-de9d62bb6ab8",
   "metadata": {},
   "source": [
    "## Machine Learning Third Home Assignment\n",
    "Group number: 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f644f8f-866b-431a-945b-db10144f305d",
   "metadata": {},
   "source": [
    "#### Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e759ca-f911-4614-9d32-942547bed1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, PowerTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81672bd5-371d-4c00-a761-9a0a3915bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "X_TRAIN, X_ivs, y_TRAIN, col_names = pickle.load(open(\"drd2_data.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c709ef5",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f5a302-bd5c-4222-ac17-5758295c1827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplistic evaluation function running Random Forest, Decision Tree and Linear Regression, and producing the RVE for each \n",
    "def naif_model_testingR(X_train, X_test, y_train, y_test):\n",
    "    #test 3 approaches and print out the results\n",
    "    \n",
    "    rfr= RandomForestRegressor(n_estimators=10)\n",
    "    rfr.fit(X_train, y_train)\n",
    "\n",
    "    dtr= DecisionTreeRegressor(max_depth=5)\n",
    "    dtr.fit(X_train, y_train)\n",
    "\n",
    "    lmr=LinearRegression()\n",
    "    lmr.fit(X_train, y_train)\n",
    "\n",
    "    rf_preds=rfr.predict(X_test)\n",
    "    dt_preds=dtr.predict(X_test)\n",
    "    lr_preds=lmr.predict(X_test)\n",
    "\n",
    "    print(\"RVE RFs: %7.4f\" % explained_variance_score(y_test, rf_preds))\n",
    "    print(\"RVE DTs: %7.4f\" % explained_variance_score(y_test, dt_preds))\n",
    "    print(\"RVE LRs: %7.4f\" % explained_variance_score(y_test, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f233d872-dd4e-422f-b02b-8d3ccb03f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runner function\n",
    "def runner(scaler, modeler, X_train, y_train, X_test):\n",
    "    scaler.fit(X_train)\n",
    "    Xt_train = scaler.transform(X_train)\n",
    "    Xt_test = scaler.transform(X_test)\n",
    "    modeler.fit(Xt_train, y_train)\n",
    "    return modeler.predict(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfbd78d8-82ca-4fe3-ad60-8f63228cf82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RVE function\n",
    "def calculate_rve(y_test, preds, run, model, results):\n",
    "    rve = explained_variance_score(y_test, preds)\n",
    "    results.append({\n",
    "        'Run': str(run),\n",
    "        'Scaler': str(scaler),\n",
    "        'Model': str(model),\n",
    "        'RVE': rve\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04ed19-3894-49ed-aff5-c07e562d914d",
   "metadata": {},
   "source": [
    "### Step 0. Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689aec88-8dcb-4a16-a10d-5fdec51ae327",
   "metadata": {},
   "source": [
    "#### 0.1 Examining X_TRAIN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9287d3-819a-4a0f-a6a2-76f175ab9d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "X_TRAIN.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc9e8286-76d4-4be7-b28e-fb281356b259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Column names\n",
    "print(X_TRAIN.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff75db8-232d-4626-820b-af82892abaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7337, 2132)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array shape\n",
    "X_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc6bec07-031d-4697-9d45-649d52811940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2122</th>\n",
       "      <th>2123</th>\n",
       "      <th>2124</th>\n",
       "      <th>2125</th>\n",
       "      <th>2126</th>\n",
       "      <th>2127</th>\n",
       "      <th>2128</th>\n",
       "      <th>2129</th>\n",
       "      <th>2130</th>\n",
       "      <th>2131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>430.518010</td>\n",
       "      <td>431.037078</td>\n",
       "      <td>5.430285</td>\n",
       "      <td>1.206897</td>\n",
       "      <td>6.527327</td>\n",
       "      <td>1.128799</td>\n",
       "      <td>4.678070</td>\n",
       "      <td>30.497615</td>\n",
       "      <td>59.165190</td>\n",
       "      <td>6.594930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396211</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.031075</td>\n",
       "      <td>0.088456</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>0.011040</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>0.038026</td>\n",
       "      <td>0.094725</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>181.613020</td>\n",
       "      <td>181.757699</td>\n",
       "      <td>4.160569</td>\n",
       "      <td>2.527815</td>\n",
       "      <td>5.983082</td>\n",
       "      <td>2.218665</td>\n",
       "      <td>2.789156</td>\n",
       "      <td>12.882724</td>\n",
       "      <td>25.749585</td>\n",
       "      <td>4.403703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489143</td>\n",
       "      <td>0.188283</td>\n",
       "      <td>0.173533</td>\n",
       "      <td>0.283976</td>\n",
       "      <td>0.164031</td>\n",
       "      <td>0.104497</td>\n",
       "      <td>0.133912</td>\n",
       "      <td>0.191273</td>\n",
       "      <td>0.292855</td>\n",
       "      <td>0.188283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>135.068414</td>\n",
       "      <td>135.166000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>357.124405</td>\n",
       "      <td>357.429000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>419.107040</td>\n",
       "      <td>419.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>472.228141</td>\n",
       "      <td>472.888000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3768.848446</td>\n",
       "      <td>3771.262000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2            3            4     \\\n",
       "count  7337.000000  7337.000000  7337.000000  7337.000000  7337.000000   \n",
       "mean    430.518010   431.037078     5.430285     1.206897     6.527327   \n",
       "std     181.613020   181.757699     4.160569     2.527815     5.983082   \n",
       "min     135.068414   135.166000     1.000000     0.000000     0.000000   \n",
       "25%     357.124405   357.429000     4.000000     0.000000     4.000000   \n",
       "50%     419.107040   419.500000     5.000000     1.000000     6.000000   \n",
       "75%     472.228141   472.888000     6.000000     1.000000     8.000000   \n",
       "max    3768.848446  3771.262000    92.000000    47.000000   137.000000   \n",
       "\n",
       "              5            6            7            8            9     ...  \\\n",
       "count  7337.000000  7337.000000  7337.000000  7337.000000  7337.000000  ...   \n",
       "mean      1.128799     4.678070    30.497615    59.165190     6.594930  ...   \n",
       "std       2.218665     2.789156    12.882724    25.749585     4.403703  ...   \n",
       "min       0.000000     0.000000    10.000000    19.000000     1.000000  ...   \n",
       "25%       0.000000     3.000000    25.000000    49.000000     5.000000  ...   \n",
       "50%       1.000000     4.000000    30.000000    57.000000     6.000000  ...   \n",
       "75%       1.000000     6.000000    33.000000    65.000000     8.000000  ...   \n",
       "max      42.000000    58.000000   266.000000   527.000000    93.000000  ...   \n",
       "\n",
       "              2122         2123         2124         2125         2126  \\\n",
       "count  7337.000000  7337.000000  7337.000000  7337.000000  7337.000000   \n",
       "mean      0.396211     0.036800     0.031075     0.088456     0.027668   \n",
       "std       0.489143     0.188283     0.173533     0.283976     0.164031   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              2127         2128         2129         2130         2131  \n",
       "count  7337.000000  7337.000000  7337.000000  7337.000000  7337.000000  \n",
       "mean      0.011040     0.018264     0.038026     0.094725     0.036800  \n",
       "std       0.104497     0.133912     0.191273     0.292855     0.188283  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 2132 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array to data.frame\n",
    "dfx = pd.DataFrame(X_TRAIN)\n",
    "# Dataset basic descriptive statistics\n",
    "dfx.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f53011-c13a-4539-8394-590e03fbf9fc",
   "metadata": {},
   "source": [
    "#### 0.2 Examining y_TRAIN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c62441c6-b4bb-4dca-906c-7fd0679db3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "y_TRAIN.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "105b070f-aabb-49ca-8080-63cdd4f59aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Column names\n",
    "print(y_TRAIN.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "001d3c1b-6223-44cc-ae80-2b8bd87ead77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7337,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array shape\n",
    "y_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65bf9875-4ec2-4669-977f-b6cbca9523c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.388388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.276656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.169187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.382177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.581929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  7337.000000\n",
       "mean      0.388388\n",
       "std       0.276656\n",
       "min       0.000000\n",
       "25%       0.169187\n",
       "50%       0.382177\n",
       "75%       0.581929\n",
       "max       1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array to data.frame\n",
    "dfy = pd.DataFrame(y_TRAIN)\n",
    "# Dataset basic descriptive statistics\n",
    "dfy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a9d34-da76-4e01-9b1b-9ff16ad086c2",
   "metadata": {},
   "source": [
    "#### 0.3 Examining X_ivs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f994ed4-d1cb-42b5-8110-3e8297b79302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "X_ivs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acba3501-9192-41f2-aec1-09b8d2d545c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Column names\n",
    "print(X_ivs.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f258b9d6-7726-47e5-82d0-b53f37791d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(816, 2132)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array shape\n",
    "X_ivs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0571b8d9-b452-48a6-b754-4afcd5410147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2122</th>\n",
       "      <th>2123</th>\n",
       "      <th>2124</th>\n",
       "      <th>2125</th>\n",
       "      <th>2126</th>\n",
       "      <th>2127</th>\n",
       "      <th>2128</th>\n",
       "      <th>2129</th>\n",
       "      <th>2130</th>\n",
       "      <th>2131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.00000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.00000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>424.093046</td>\n",
       "      <td>424.60449</td>\n",
       "      <td>5.237745</td>\n",
       "      <td>1.134804</td>\n",
       "      <td>6.387255</td>\n",
       "      <td>1.050245</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>30.093137</td>\n",
       "      <td>58.547794</td>\n",
       "      <td>6.383578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378676</td>\n",
       "      <td>0.035539</td>\n",
       "      <td>0.03799</td>\n",
       "      <td>0.089461</td>\n",
       "      <td>0.030637</td>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>0.115196</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>148.934984</td>\n",
       "      <td>149.07467</td>\n",
       "      <td>3.084869</td>\n",
       "      <td>1.902266</td>\n",
       "      <td>4.250966</td>\n",
       "      <td>1.697685</td>\n",
       "      <td>2.274514</td>\n",
       "      <td>10.606568</td>\n",
       "      <td>20.616395</td>\n",
       "      <td>3.471698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485355</td>\n",
       "      <td>0.185252</td>\n",
       "      <td>0.19129</td>\n",
       "      <td>0.285583</td>\n",
       "      <td>0.172439</td>\n",
       "      <td>0.115391</td>\n",
       "      <td>0.138733</td>\n",
       "      <td>0.175742</td>\n",
       "      <td>0.319454</td>\n",
       "      <td>0.194227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>191.131014</td>\n",
       "      <td>191.27400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>351.193555</td>\n",
       "      <td>351.77700</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>416.657121</td>\n",
       "      <td>417.25450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>472.236208</td>\n",
       "      <td>472.58500</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1635.822461</td>\n",
       "      <td>1637.00900</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4     \\\n",
       "count   816.000000   816.00000  816.000000  816.000000  816.000000   \n",
       "mean    424.093046   424.60449    5.237745    1.134804    6.387255   \n",
       "std     148.934984   149.07467    3.084869    1.902266    4.250966   \n",
       "min     191.131014   191.27400    1.000000    0.000000    0.000000   \n",
       "25%     351.193555   351.77700    4.000000    0.000000    4.000000   \n",
       "50%     416.657121   417.25450    5.000000    1.000000    6.000000   \n",
       "75%     472.236208   472.58500    6.000000    1.000000    8.000000   \n",
       "max    1635.822461  1637.00900   36.000000   20.000000   51.000000   \n",
       "\n",
       "             5           6           7           8           9     ...  \\\n",
       "count  816.000000  816.000000  816.000000  816.000000  816.000000  ...   \n",
       "mean     1.050245    4.583333   30.093137   58.547794    6.383578  ...   \n",
       "std      1.697685    2.274514   10.606568   20.616395    3.471698  ...   \n",
       "min      0.000000    1.000000   14.000000   26.000000    1.000000  ...   \n",
       "25%      0.000000    3.000000   25.000000   49.000000    4.000000  ...   \n",
       "50%      1.000000    4.000000   30.000000   57.000000    6.000000  ...   \n",
       "75%      1.000000    6.000000   33.000000   64.000000    8.000000  ...   \n",
       "max     18.000000   22.000000  118.000000  228.000000   37.000000  ...   \n",
       "\n",
       "             2122        2123       2124        2125        2126        2127  \\\n",
       "count  816.000000  816.000000  816.00000  816.000000  816.000000  816.000000   \n",
       "mean     0.378676    0.035539    0.03799    0.089461    0.030637    0.013480   \n",
       "std      0.485355    0.185252    0.19129    0.285583    0.172439    0.115391   \n",
       "min      0.000000    0.000000    0.00000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.00000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.00000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    0.000000    0.00000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.00000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             2128        2129        2130        2131  \n",
       "count  816.000000  816.000000  816.000000  816.000000  \n",
       "mean     0.019608    0.031863    0.115196    0.039216  \n",
       "std      0.138733    0.175742    0.319454    0.194227  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 2132 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array to data.frame\n",
    "dfi = pd.DataFrame(X_ivs)\n",
    "# Dataset basic descriptive statistics\n",
    "dfi.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb40e4-b428-4412-845d-95231a7abcdf",
   "metadata": {},
   "source": [
    "#### 0.4 Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a047a0a5-2c23-4fcc-aad2-d29b68494165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN in the X_TRAIN:  0\n",
      "Number of NaN in the y_TRAIN:  0\n",
      "Number of NaN in the X_ivs:    0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaN in the X_TRAIN: \", np.count_nonzero(np.isnan(X_TRAIN)))\n",
    "print(\"Number of NaN in the y_TRAIN: \", np.count_nonzero(np.isnan(y_TRAIN)))\n",
    "print(\"Number of NaN in the X_ivs:   \", np.count_nonzero(np.isnan(X_ivs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9aee41a-ed94-471c-b13b-c46ba6f655df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of '?' in the X_TRAIN:  0\n",
      "Number of '?' in the y_TRAIN:  0\n",
      "Number of '?' in the X_ivs:    0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/kcl1g93d2lqfgmbbh785y7900000gn/T/ipykernel_40475/4278104260.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  print(\"Number of '?' in the X_TRAIN: \", np.count_nonzero(X_TRAIN=='?'))\n",
      "/var/folders/p_/kcl1g93d2lqfgmbbh785y7900000gn/T/ipykernel_40475/4278104260.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  print(\"Number of '?' in the y_TRAIN: \", np.count_nonzero(y_TRAIN=='?'))\n",
      "/var/folders/p_/kcl1g93d2lqfgmbbh785y7900000gn/T/ipykernel_40475/4278104260.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  print(\"Number of '?' in the X_ivs:   \", np.count_nonzero(X_ivs=='?'))\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of '?' in the X_TRAIN: \", np.count_nonzero(X_TRAIN=='?'))\n",
    "print(\"Number of '?' in the y_TRAIN: \", np.count_nonzero(y_TRAIN=='?'))\n",
    "print(\"Number of '?' in the X_ivs:   \", np.count_nonzero(X_ivs=='?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9233a3f-f629-46bb-86e5-7bb2f2fc106d",
   "metadata": {},
   "source": [
    "## Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837831aa-cf5c-436b-abf3-02e239138196",
   "metadata": {},
   "source": [
    "### Step 1. Split the data set into a training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91856fa-f341-4f5a-bd75-f177d26e8cf8",
   "metadata": {},
   "source": [
    "#### 1.1 Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8dc4970-d6b4-4885-9208-095780b7cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_TRAIN, y_TRAIN, test_size = 0.25, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5416b-236b-4979-9959-d0687bc0c1f4",
   "metadata": {},
   "source": [
    "#### 1.2 Naif model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7f22363-3dab-4228-8df3-7c6f347202c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RVE RFs:  0.6108\n",
      "RVE DTs:  0.3091\n",
      "RVE LRs:  0.4054\n"
     ]
    }
   ],
   "source": [
    "naif_model_testingR(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26568d33-ab8a-4735-bbeb-f6311987cffc",
   "metadata": {},
   "source": [
    "### Step 2. Scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078d4f13",
   "metadata": {},
   "source": [
    "#### 2.1 Finding the best scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f6e41-a580-42b7-b2a2-2a3c32d635bb",
   "metadata": {},
   "source": [
    "Note: did not use \"scaler = PowerTransformer()\" because it yields the error \"RuntimeWarning: overflow encountered in multiply\n",
    "  x = um.multiply(x, x, out=x)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0da18b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Model</th>\n",
       "      <th>RVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.615382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.612799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.612194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.608931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.608862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run            Scaler                                   Model       RVE\n",
       "21   2  StandardScaler()  RandomForestRegressor(n_estimators=10)  0.615382\n",
       "9    1    MinMaxScaler()  RandomForestRegressor(n_estimators=10)  0.612799\n",
       "24   2      Normalizer()  RandomForestRegressor(n_estimators=10)  0.612194\n",
       "12   1  StandardScaler()  RandomForestRegressor(n_estimators=10)  0.608931\n",
       "18   2    MinMaxScaler()  RandomForestRegressor(n_estimators=10)  0.608862"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = range(5)\n",
    "scalers = [MinMaxScaler(), StandardScaler(), Normalizer()]\n",
    "models = [RandomForestRegressor(n_estimators=10), DecisionTreeRegressor(max_depth=5), LinearRegression()]\n",
    "results = []\n",
    "\n",
    "for run in runs:\n",
    "    for scaler in scalers:\n",
    "        for model in models:\n",
    "            preds = runner(scaler, model, X_train, y_train, X_test)\n",
    "            calculate_rve(y_test, preds, run, model, results)\n",
    "\n",
    "rve_table_scalers = pd.DataFrame(results)\n",
    "rve_table_scalers = rve_table_scalers.sort_values(by = 'RVE', ascending = False)\n",
    "rve_table_scalers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9214c-7ddf-4fb8-9e1d-c2b5575ad9fa",
   "metadata": {},
   "source": [
    "Different runs yield different \"best scaler\". The three tested scalers perform identically, with MinMaxScaler() being the one that is more often the \"best scaler\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7999834a",
   "metadata": {},
   "source": [
    "#### 2.2 Apply the selected scaler to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98423229-19e0-406f-9a83-c3816215f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_s = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b68c1-56e9-41ca-abae-c88c5d857a4a",
   "metadata": {},
   "source": [
    "### Step 3. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc0988-9a07-43e4-87f7-b6a6787ca059",
   "metadata": {},
   "source": [
    "#### 3.1 Identify the most important features and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "727764f7-97aa-4f8c-bca2-214231858808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>RVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.652071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.650977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.649729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.649729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.618857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Threshold       RVE\n",
       "3  1.000000e-04  0.652071\n",
       "2  1.000000e-05  0.650977\n",
       "0  1.000000e-07  0.649729\n",
       "1  1.000000e-06  0.649729\n",
       "4  1.000000e-03  0.618857"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify and evaluate the most important features using the SelectFromModel class\n",
    "res_fs = []\n",
    "rfr = RandomForestRegressor(random_state = 4)\n",
    "t_range = [0.0000001, 0.000001, 0.00001, 0.0001, 0.001]\n",
    "for t in t_range:\n",
    "    sel = SelectFromModel(estimator = rfr, threshold = t)\n",
    "    sel.fit(X_train_s, y_train)\n",
    "    X_train_s_fs = sel.transform(X_train_s)\n",
    "    X_test_s_fs = sel.transform(X_test_s)\n",
    "    rfr.fit(X_train_s_fs, y_train)\n",
    "    rfr_preds = rfr.predict(X_test_s_fs)\n",
    "    res_fs.append({'Threshold': t, 'RVE': explained_variance_score(y_test, rfr_preds)})\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "res_fs = pd.DataFrame(res_fs)\n",
    "res_fs = res_fs.sort_values(by = \"RVE\", ascending = False)\n",
    "res_fs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30d9ae83-91ca-43f5-831b-8ac4021a1e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot RVE vs Threshold\n",
    "res_fs.plot(x = 'Threshold', y = 'RVE', style = 'o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('RVE')\n",
    "plt.legend('', frameon = False)\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff22f86f-afce-49a8-9eed-312b63c0ed78",
   "metadata": {},
   "source": [
    "#### 3.2 Selected features - transforming dataset by keeping the \"best\" set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de5c523b-4355-454b-b4cf-e543a8f97a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state = 4)\n",
    "N,M = X_train_s.shape\n",
    "sel = SelectFromModel(estimator = rfr, threshold = 0.0001)\n",
    "sel.fit(X_train_s, y_train)\n",
    "features = sel.get_support()\n",
    "Features_selected = np.arange(M)[features]\n",
    "X_train_s_fs = sel.transform(X_train_s)\n",
    "X_test_s_fs = sel.transform(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1bc89c8-c72e-415b-85db-8ca790ebef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected:  1306 out of the initial 2132 (61.3 %)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features selected: \", len (Features_selected), \"out of the initial\", M, \"(%4.1f\"%(((len (Features_selected))/M)*100),\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4125b61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RVE RFs:  0.6135\n",
      "RVE DTs:  0.3091\n",
      "RVE LRs:  0.5032\n"
     ]
    }
   ],
   "source": [
    "naif_model_testingR(X_train_s_fs, X_test_s_fs, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec4ead-7d4b-4878-b9d2-505e88926da5",
   "metadata": {},
   "source": [
    "### Step 4. Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc2ce4-d0c1-43ba-8ab9-dcc69a6bd28b",
   "metadata": {},
   "source": [
    "#### 4.1 Evaluate number of PCs vs total variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "993896d5-e4fb-4174-8e13-0e40a98184d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 497PCs Total Variance Explained:  0.9000\n",
      "First 498PCs Total Variance Explained:  0.9003\n",
      "First 499PCs Total Variance Explained:  0.9005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 500)\n",
    "pca.fit(X_train_s_fs)\n",
    "tve = 0\n",
    "for i, ve in enumerate(pca.explained_variance_ratio_):\n",
    "    tve += ve\n",
    "    if tve > 0.90:\n",
    "        print(\"First %dPCs Total Variance Explained: %7.4f\" % (i, tve))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a89887-3e4d-4c7b-b403-56c2f7fc8caf",
   "metadata": {},
   "source": [
    "#### 4.2 Use Kernel PCA to determine number of PCs to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88687286",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    ('RandomForest', RandomForestRegressor()),\n",
    "    ('LinearRegression', LinearRegression()),\n",
    "    ('SVR', SVR()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('XGBR',XGBRegressor()),\n",
    "    ('MLPR', MLPRegressor())\n",
    "]\n",
    "\n",
    "# Create a list of pipelines with different regressors\n",
    "pipelines = []\n",
    "for regressor_name, regressor_instance in regressors:\n",
    "    pipeline = Pipeline([\n",
    "        ('kpca', KernelPCA()),\n",
    "        ('regressor', regressor_instance)\n",
    "    ])\n",
    "    pipelines.append((regressor_name, pipeline))\n",
    "    \n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'kpca__n_components': [200, 500, 800, 1306],\n",
    "    'kpca__kernel': [\"poly\", \"cosine\"],\n",
    "    'kpca__gamma': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_pca = pd.DataFrame(columns=['Regressor', 'Best Parameters', 'Best Explained Variance', 'RVE on Test Set'])\n",
    "\n",
    "# Iterate over pipelines and perform GridSearchCV\n",
    "for regressor_name, pipeline in pipelines:\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='explained_variance')\n",
    "    grid_search.fit(X_train_s_fs, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Use the best estimator for prediction\n",
    "    preds = best_model.predict(X_test_s_fs)\n",
    "    \n",
    "    # Calculate RVE on the test set\n",
    "    rve = explained_variance_score(y_test, preds)\n",
    "    \n",
    "    # Append results to the DataFrame\n",
    "    results_pca = pd.concat([results_pca, pd.DataFrame({\n",
    "        'Regressor': [regressor_name],\n",
    "        'Best Parameters': [str(grid_search.best_params_)],\n",
    "        'Best Explained Variance': [grid_search.best_score_],\n",
    "        'RVE on Test Set': [rve]\n",
    "    })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a41a750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regressor</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Explained Variance</th>\n",
       "      <th>RVE on Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'kpca__gamma': 1, 'kpca__kernel': 'cosine', 'kpca__n_components': 500}</td>\n",
       "      <td>0.636321</td>\n",
       "      <td>0.656097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'kpca__gamma': 1, 'kpca__kernel': 'poly', 'kpca__n_components': 1306}</td>\n",
       "      <td>0.608339</td>\n",
       "      <td>0.633993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPR</td>\n",
       "      <td>{'kpca__gamma': 1, 'kpca__kernel': 'cosine', 'kpca__n_components': 200}</td>\n",
       "      <td>0.600641</td>\n",
       "      <td>0.620812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'kpca__gamma': 1, 'kpca__kernel': 'cosine', 'kpca__n_components': 800}</td>\n",
       "      <td>0.603649</td>\n",
       "      <td>0.617737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBR</td>\n",
       "      <td>{'kpca__gamma': 3, 'kpca__kernel': 'poly', 'kpca__n_components': 500}</td>\n",
       "      <td>0.555373</td>\n",
       "      <td>0.589615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'kpca__gamma': 5, 'kpca__kernel': 'poly', 'kpca__n_components': 200}</td>\n",
       "      <td>0.574210</td>\n",
       "      <td>0.579748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Regressor  \\\n",
       "2               SVR   \n",
       "1  LinearRegression   \n",
       "5              MLPR   \n",
       "3               KNN   \n",
       "4              XGBR   \n",
       "0      RandomForest   \n",
       "\n",
       "                                                           Best Parameters  \\\n",
       "2  {'kpca__gamma': 1, 'kpca__kernel': 'cosine', 'kpca__n_components': 500}   \n",
       "1   {'kpca__gamma': 1, 'kpca__kernel': 'poly', 'kpca__n_components': 1306}   \n",
       "5  {'kpca__gamma': 1, 'kpca__kernel': 'cosine', 'kpca__n_components': 200}   \n",
       "3  {'kpca__gamma': 1, 'kpca__kernel': 'cosine', 'kpca__n_components': 800}   \n",
       "4    {'kpca__gamma': 3, 'kpca__kernel': 'poly', 'kpca__n_components': 500}   \n",
       "0    {'kpca__gamma': 5, 'kpca__kernel': 'poly', 'kpca__n_components': 200}   \n",
       "\n",
       "   Best Explained Variance  RVE on Test Set  \n",
       "2                 0.636321         0.656097  \n",
       "1                 0.608339         0.633993  \n",
       "5                 0.600641         0.620812  \n",
       "3                 0.603649         0.617737  \n",
       "4                 0.555373         0.589615  \n",
       "0                 0.574210         0.579748  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "results_pca = results_pca.sort_values(by='RVE on Test Set', ascending=False)\n",
    "results_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a74b90-8409-41e5-bce6-7a281db05281",
   "metadata": {},
   "source": [
    "#### 4.3 Transform data with Kernel PCA / number of PCs to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b71551e4-cb67-415e-b4b8-e0fb1db26072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KernelPCA\n",
    "kpca = KernelPCA(n_components = 500, kernel = 'cosine', gamma = 1)\n",
    "kpca.fit(X_train_s_fs)\n",
    "X_train_s_fs_pca = kpca.transform(X_train_s_fs)\n",
    "X_test_s_fs_pca = kpca.transform(X_test_s_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3cb65-b48d-499c-af13-f2c13601f7b4",
   "metadata": {},
   "source": [
    "### Step 5. Fitting and tuning the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36655f65-6367-4301-a46e-12aca36ed5c4",
   "metadata": {},
   "source": [
    "#### 5.1 Testing models and hyperparameters for data with Kernel PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "430e5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LinearRegression...\n",
      "Processing Ridge...\n",
      "Processing Lasso...\n",
      "Processing ElasticNet...\n",
      "Processing DecisionTreeRegressor...\n",
      "Processing KNeighborsRegressor...\n",
      "Processing SVR...\n",
      "Processing RandomForestRegressor...\n",
      "Processing AdaBoostRegressor...\n",
      "Processing GradientBoostingRegressor...\n",
      "Processing XGBRegressor...\n",
      "Processing MLPRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "linear_regression = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "elastic_net = ElasticNet()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "svm_regressor = SVR()\n",
    "random_forest = RandomForestRegressor()\n",
    "abr = AdaBoostRegressor()\n",
    "gradient_boosting = GradientBoostingRegressor()\n",
    "xgboost_regressor = XGBRegressor()\n",
    "nnr = MLPRegressor()\n",
    "\n",
    "# Define hyperparameter grids\n",
    "param_grid_linear_regression = {}\n",
    "param_grid_ridge = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_lasso = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_elastic_net = {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "param_grid_decision_tree = {'max_depth': [None, 10, 20, 30], 'min_samples_leaf': [1, 5, 10, 20]}\n",
    "param_knn = {'n_neighbors': [1, 5, 10, 20], 'weights': ['uniform', 'distance']}\n",
    "param_grid_svm = {'gamma': [1e-1, 1e-7, 'scale'], 'C': [1, 10, 100], 'epsilon': [0.001, 0.1, 0.3]}\n",
    "param_grid_random_forest = {'n_estimators': [10, 100], 'max_depth': [None, 30]}\n",
    "param_abr = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "param_grid_gradient_boosting = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}\n",
    "param_grid_xgboost = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, None]}\n",
    "param_grid_nnr= {'hidden_layer_sizes': [(100, 100)], 'solver': ['lbfgs', 'sgd', 'adam'], 'alpha': [0.0001, 0.01, 0.1, 1], 'max_iter': [2000]}\n",
    "\n",
    "results_withpca = pd.DataFrame(columns=['Model', 'Best Parameters', 'Best Explained Variance', 'RVE on Test Set'])\n",
    "\n",
    "# Create a list of models and their respective parameter grids\n",
    "models = [\n",
    "    (linear_regression, param_grid_linear_regression),\n",
    "    (ridge, param_grid_ridge),\n",
    "    (lasso, param_grid_lasso),\n",
    "    (elastic_net, param_grid_elastic_net),\n",
    "    (decision_tree, param_grid_decision_tree),\n",
    "    (knn, param_knn),\n",
    "    (svm_regressor, param_grid_svm),\n",
    "    (random_forest, param_grid_random_forest),\n",
    "    (abr, param_abr),\n",
    "    (gradient_boosting, param_grid_gradient_boosting),\n",
    "    (xgboost_regressor, param_grid_xgboost),\n",
    "    (nnr, param_grid_nnr)\n",
    "]\n",
    "\n",
    "# Iterate over models and perform GridSearchCV\n",
    "for model, param_grid in models:\n",
    "    print(f\"Processing {model.__class__.__name__}...\")\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='explained_variance', n_jobs=-1)\n",
    "    grid_search.fit(X_train_s_fs_pca, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Use the best estimator for prediction\n",
    "    preds = best_model.predict(X_test_s_fs_pca)\n",
    "    \n",
    "    # Calculate RVE on the test set\n",
    "    rve = explained_variance_score(y_test, preds)\n",
    "    \n",
    "    # Append results to the DataFrame\n",
    "    results_withpca = pd.concat([results_withpca, pd.DataFrame({\n",
    "        'Model': [model.__class__.__name__],\n",
    "        'Best Parameters': [str(grid_search.best_params_)],\n",
    "        'Best Explained Variance': [grid_search.best_score_],\n",
    "        'RVE on Test Set': [rve]\n",
    "    })], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae9fd80-1eb8-408b-bada-7a27056efcdb",
   "metadata": {},
   "source": [
    "#### 5.2 Testing models and hyperparameters for data without Kernel PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2577fcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LinearRegression...\n",
      "Processing Ridge...\n",
      "Processing Lasso...\n",
      "Processing ElasticNet...\n",
      "Processing DecisionTreeRegressor...\n",
      "Processing KNeighborsRegressor...\n",
      "Processing SVR...\n",
      "Processing RandomForestRegressor...\n",
      "Processing AdaBoostRegressor...\n",
      "Processing GradientBoostingRegressor...\n",
      "Processing XGBRegressor...\n",
      "Processing MLPRegressor...\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "linear_regression = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "elastic_net = ElasticNet()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "svm_regressor = SVR()\n",
    "random_forest = RandomForestRegressor()\n",
    "abr = AdaBoostRegressor()\n",
    "gradient_boosting = GradientBoostingRegressor()\n",
    "xgboost_regressor = XGBRegressor()\n",
    "nnr = MLPRegressor()\n",
    "\n",
    "# Define hyperparameter grids\n",
    "param_grid_linear_regression = {}\n",
    "param_grid_ridge = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_lasso = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_elastic_net = {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "param_grid_decision_tree = {'max_depth': [None, 10, 20, 30], 'min_samples_leaf': [1, 5, 10, 20]}\n",
    "param_knn = {'n_neighbors': [1, 5, 10, 20], 'weights': ['uniform', 'distance']}\n",
    "param_grid_svm = {'gamma': [1e-1, 1e-7, 'scale'], 'C': [1, 10, 100], 'epsilon': [0.001, 0.1, 0.3]}\n",
    "param_grid_random_forest = {'n_estimators': [10, 100], 'max_depth': [None, 30]}\n",
    "param_abr = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "param_grid_gradient_boosting = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}\n",
    "param_grid_xgboost = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, None]}\n",
    "param_grid_nnr= {'hidden_layer_sizes': [(100, 100)], 'solver': ['lbfgs', 'sgd', 'adam'], 'alpha': [0.0001, 0.01, 0.1, 1], 'max_iter': [2000]}\n",
    "\n",
    "results_withoutpc = pd.DataFrame(columns=['Model', 'Best Parameters', 'Best Explained Variance', 'RVE on Test Set'])\n",
    "\n",
    "# Create a list of models and their respective parameter grids\n",
    "models = [\n",
    "    (linear_regression, param_grid_linear_regression),\n",
    "    (ridge, param_grid_ridge),\n",
    "    (lasso, param_grid_lasso),\n",
    "    (elastic_net, param_grid_elastic_net),\n",
    "    (decision_tree, param_grid_decision_tree),\n",
    "    (knn, param_knn),\n",
    "    (svm_regressor, param_grid_svm),\n",
    "    (random_forest, param_grid_random_forest),\n",
    "    (abr, param_abr),\n",
    "    (gradient_boosting, param_grid_gradient_boosting),\n",
    "    (xgboost_regressor, param_grid_xgboost),\n",
    "    (nnr, param_grid_nnr)\n",
    "]\n",
    "\n",
    "# Iterate over models and perform GridSearchCV\n",
    "for model, param_grid in models:\n",
    "    print(f\"Processing {model.__class__.__name__}...\")\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='explained_variance', n_jobs=-1)\n",
    "    grid_search.fit(X_train_s_fs, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Use the best estimator for prediction\n",
    "    preds = best_model.predict(X_test_s_fs)\n",
    "    \n",
    "    # Calculate RVE on the test set\n",
    "    rve = explained_variance_score(y_test, preds)\n",
    "    \n",
    "    # Append results to the DataFrame\n",
    "    results_withoutpc = pd.concat([results_withoutpc, pd.DataFrame({\n",
    "        'Model': [model.__class__.__name__],\n",
    "        'Best Parameters': [str(grid_search.best_params_)],\n",
    "        'Best Explained Variance': [grid_search.best_score_],\n",
    "        'RVE on Test Set': [rve]\n",
    "    })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e1886-0a3b-4bb2-89e2-a1561b2a77f0",
   "metadata": {},
   "source": [
    "### Step 6. Assessing the quality of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56318c13",
   "metadata": {},
   "source": [
    "#### 6.1 Data with Kernel PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b77aef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Explained Variance</th>\n",
       "      <th>RVE on Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}</td>\n",
       "      <td>0.648912</td>\n",
       "      <td>0.674853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.603229</td>\n",
       "      <td>0.630546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'alpha': 0.01, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'adam'}</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.611589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}</td>\n",
       "      <td>0.533366</td>\n",
       "      <td>0.562455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.526246</td>\n",
       "      <td>0.550251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.509779</td>\n",
       "      <td>0.545052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.498118</td>\n",
       "      <td>0.521916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.480398</td>\n",
       "      <td>0.517790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.190588</td>\n",
       "      <td>0.243024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100}</td>\n",
       "      <td>0.191345</td>\n",
       "      <td>0.182234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.001313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "6                         SVR   \n",
       "5         KNeighborsRegressor   \n",
       "11               MLPRegressor   \n",
       "10               XGBRegressor   \n",
       "1                       Ridge   \n",
       "0            LinearRegression   \n",
       "9   GradientBoostingRegressor   \n",
       "7       RandomForestRegressor   \n",
       "4       DecisionTreeRegressor   \n",
       "8           AdaBoostRegressor   \n",
       "3                  ElasticNet   \n",
       "2                       Lasso   \n",
       "\n",
       "                                                                          Best Parameters  \\\n",
       "6                                            {'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}   \n",
       "5                                               {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "11  {'alpha': 0.01, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'adam'}   \n",
       "10                         {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}   \n",
       "1                                                                          {'alpha': 1.0}   \n",
       "0                                                                                      {}   \n",
       "9                             {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}   \n",
       "7                                                {'max_depth': None, 'n_estimators': 100}   \n",
       "4                                               {'max_depth': 10, 'min_samples_leaf': 20}   \n",
       "8                                             {'learning_rate': 0.1, 'n_estimators': 100}   \n",
       "3                                                         {'alpha': 0.1, 'l1_ratio': 0.1}   \n",
       "2                                                                          {'alpha': 0.1}   \n",
       "\n",
       "    Best Explained Variance  RVE on Test Set  \n",
       "6                  0.648912         0.674853  \n",
       "5                  0.603229         0.630546  \n",
       "11                 0.609431         0.611589  \n",
       "10                 0.533366         0.562455  \n",
       "1                  0.526246         0.550251  \n",
       "0                  0.509779         0.545052  \n",
       "9                  0.498118         0.521916  \n",
       "7                  0.480398         0.517790  \n",
       "4                  0.190588         0.243024  \n",
       "8                  0.191345         0.182234  \n",
       "3                  0.001156         0.001313  \n",
       "2                  0.000000         0.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "# Sort the DataFrame based on RVE in descending order\n",
    "results_withpca = results_withpca.sort_values(by='RVE on Test Set', ascending=False)\n",
    "results_withpca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7cd50",
   "metadata": {},
   "source": [
    "#### 6.1 Data without Kernel PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30abb277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Explained Variance</th>\n",
       "      <th>RVE on Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}</td>\n",
       "      <td>0.644669</td>\n",
       "      <td>0.681507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}</td>\n",
       "      <td>0.620122</td>\n",
       "      <td>0.652017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.603197</td>\n",
       "      <td>0.651562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.604971</td>\n",
       "      <td>0.626924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'alpha': 1, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.599880</td>\n",
       "      <td>0.618527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.559918</td>\n",
       "      <td>0.583349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.522731</td>\n",
       "      <td>0.552977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.450337</td>\n",
       "      <td>0.503177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.362862</td>\n",
       "      <td>0.426772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 50}</td>\n",
       "      <td>0.221498</td>\n",
       "      <td>0.217248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.115630</td>\n",
       "      <td>0.125381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "6                         SVR   \n",
       "10               XGBRegressor   \n",
       "7       RandomForestRegressor   \n",
       "5         KNeighborsRegressor   \n",
       "11               MLPRegressor   \n",
       "9   GradientBoostingRegressor   \n",
       "1                       Ridge   \n",
       "0            LinearRegression   \n",
       "4       DecisionTreeRegressor   \n",
       "8           AdaBoostRegressor   \n",
       "3                  ElasticNet   \n",
       "2                       Lasso   \n",
       "\n",
       "                                                                        Best Parameters  \\\n",
       "6                                          {'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}   \n",
       "10                       {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}   \n",
       "7                                              {'max_depth': None, 'n_estimators': 100}   \n",
       "5                                             {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "11  {'alpha': 1, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'lbfgs'}   \n",
       "9                           {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}   \n",
       "1                                                                       {'alpha': 10.0}   \n",
       "0                                                                                    {}   \n",
       "4                                             {'max_depth': 20, 'min_samples_leaf': 10}   \n",
       "8                                            {'learning_rate': 0.1, 'n_estimators': 50}   \n",
       "3                                                       {'alpha': 0.1, 'l1_ratio': 0.1}   \n",
       "2                                                                        {'alpha': 0.1}   \n",
       "\n",
       "    Best Explained Variance  RVE on Test Set  \n",
       "6                  0.644669         0.681507  \n",
       "10                 0.620122         0.652017  \n",
       "7                  0.603197         0.651562  \n",
       "5                  0.604971         0.626924  \n",
       "11                 0.599880         0.618527  \n",
       "9                  0.559918         0.583349  \n",
       "1                  0.522731         0.552977  \n",
       "0                  0.450337         0.503177  \n",
       "4                  0.362862         0.426772  \n",
       "8                  0.221498         0.217248  \n",
       "3                  0.115630         0.125381  \n",
       "2                  0.000000         0.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "# Sort the DataFrame based on RVE in descending order\n",
    "results_withoutpc = results_withoutpc.sort_values(by='RVE on Test Set', ascending=False)\n",
    "results_withoutpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f8a45-785d-44b2-b269-499f7b592db7",
   "metadata": {},
   "source": [
    "### Step 7. Select best models of approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42b3716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Explained Variance</th>\n",
       "      <th>RVE on Test Set</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}</td>\n",
       "      <td>0.644669</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>Without PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}</td>\n",
       "      <td>0.648912</td>\n",
       "      <td>0.674853</td>\n",
       "      <td>With PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}</td>\n",
       "      <td>0.620122</td>\n",
       "      <td>0.652017</td>\n",
       "      <td>Without PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.603197</td>\n",
       "      <td>0.651562</td>\n",
       "      <td>Without PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.603229</td>\n",
       "      <td>0.630546</td>\n",
       "      <td>With PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.604971</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>Without PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'alpha': 1, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.599880</td>\n",
       "      <td>0.618527</td>\n",
       "      <td>Without PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'alpha': 0.01, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'adam'}</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.611589</td>\n",
       "      <td>With PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.559918</td>\n",
       "      <td>0.583349</td>\n",
       "      <td>Without PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}</td>\n",
       "      <td>0.533366</td>\n",
       "      <td>0.562455</td>\n",
       "      <td>With PCA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "6                         SVR   \n",
       "6                         SVR   \n",
       "10               XGBRegressor   \n",
       "7       RandomForestRegressor   \n",
       "5         KNeighborsRegressor   \n",
       "5         KNeighborsRegressor   \n",
       "11               MLPRegressor   \n",
       "11               MLPRegressor   \n",
       "9   GradientBoostingRegressor   \n",
       "10               XGBRegressor   \n",
       "\n",
       "                                                                          Best Parameters  \\\n",
       "6                                            {'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}   \n",
       "6                                            {'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}   \n",
       "10                         {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}   \n",
       "7                                                {'max_depth': None, 'n_estimators': 100}   \n",
       "5                                               {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "5                                               {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "11    {'alpha': 1, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'lbfgs'}   \n",
       "11  {'alpha': 0.01, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'adam'}   \n",
       "9                             {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}   \n",
       "10                         {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}   \n",
       "\n",
       "    Best Explained Variance  RVE on Test Set      Dataset  \n",
       "6                  0.644669         0.681507  Without PCA  \n",
       "6                  0.648912         0.674853     With PCA  \n",
       "10                 0.620122         0.652017  Without PCA  \n",
       "7                  0.603197         0.651562  Without PCA  \n",
       "5                  0.603229         0.630546     With PCA  \n",
       "5                  0.604971         0.626924  Without PCA  \n",
       "11                 0.599880         0.618527  Without PCA  \n",
       "11                 0.609431         0.611589     With PCA  \n",
       "9                  0.559918         0.583349  Without PCA  \n",
       "10                 0.533366         0.562455     With PCA  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_withpca['Dataset'] = 'With PCA'\n",
    "results_withoutpc['Dataset'] = 'Without PCA'\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_results = pd.concat([results_withpca, results_withoutpc])\n",
    "\n",
    "# Sort the combined DataFrame based on RVE in descending order\n",
    "combined_results = combined_results.sort_values(by='RVE on Test Set', ascending=False)\n",
    "\n",
    "combined_results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9969e117",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b11d5-58d6-40dc-a9f5-0d51eba9869f",
   "metadata": {},
   "source": [
    "### Step 1. Split the data set into a training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "140c6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate continuous and binary features\n",
    "continuous_train = X_train[:, :43]\n",
    "binary_train = X_train[:, 43:]\n",
    "\n",
    "# Apply the same transformation to X_test\n",
    "continuous_test = X_test[:, :43]\n",
    "binary_test = X_test[:, 43:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37c4eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>433.139807</td>\n",
       "      <td>433.659229</td>\n",
       "      <td>5.490549</td>\n",
       "      <td>1.239549</td>\n",
       "      <td>6.606325</td>\n",
       "      <td>1.157761</td>\n",
       "      <td>4.710287</td>\n",
       "      <td>30.687023</td>\n",
       "      <td>59.501636</td>\n",
       "      <td>6.665213</td>\n",
       "      <td>...</td>\n",
       "      <td>17.728743</td>\n",
       "      <td>10.809153</td>\n",
       "      <td>6.080916</td>\n",
       "      <td>6.080916</td>\n",
       "      <td>4.375903</td>\n",
       "      <td>-2.530154</td>\n",
       "      <td>21.342164</td>\n",
       "      <td>9.604665</td>\n",
       "      <td>5.091744</td>\n",
       "      <td>6.744692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>193.011382</td>\n",
       "      <td>193.161908</td>\n",
       "      <td>4.460679</td>\n",
       "      <td>2.737377</td>\n",
       "      <td>6.442301</td>\n",
       "      <td>2.390030</td>\n",
       "      <td>2.943638</td>\n",
       "      <td>13.690007</td>\n",
       "      <td>27.377821</td>\n",
       "      <td>4.703330</td>\n",
       "      <td>...</td>\n",
       "      <td>7.816940</td>\n",
       "      <td>4.699178</td>\n",
       "      <td>2.492909</td>\n",
       "      <td>2.492909</td>\n",
       "      <td>1.793121</td>\n",
       "      <td>1.382712</td>\n",
       "      <td>11.135756</td>\n",
       "      <td>6.088213</td>\n",
       "      <td>4.193230</td>\n",
       "      <td>5.006745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>135.068414</td>\n",
       "      <td>135.166000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.593478</td>\n",
       "      <td>3.306776</td>\n",
       "      <td>1.073575</td>\n",
       "      <td>1.073575</td>\n",
       "      <td>0.534404</td>\n",
       "      <td>-25.750000</td>\n",
       "      <td>5.593184</td>\n",
       "      <td>1.904405</td>\n",
       "      <td>0.727470</td>\n",
       "      <td>1.065169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>357.140875</td>\n",
       "      <td>357.479000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.628668</td>\n",
       "      <td>8.872773</td>\n",
       "      <td>4.980925</td>\n",
       "      <td>4.980925</td>\n",
       "      <td>3.547447</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>17.284118</td>\n",
       "      <td>7.501125</td>\n",
       "      <td>3.649813</td>\n",
       "      <td>5.016531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>419.150511</td>\n",
       "      <td>419.529000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.118975</td>\n",
       "      <td>10.462253</td>\n",
       "      <td>5.830326</td>\n",
       "      <td>5.830326</td>\n",
       "      <td>4.158435</td>\n",
       "      <td>-2.380000</td>\n",
       "      <td>20.429792</td>\n",
       "      <td>9.055056</td>\n",
       "      <td>4.616490</td>\n",
       "      <td>6.220281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>473.198238</td>\n",
       "      <td>473.853750</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.190916</td>\n",
       "      <td>11.794588</td>\n",
       "      <td>6.695303</td>\n",
       "      <td>6.695303</td>\n",
       "      <td>4.892010</td>\n",
       "      <td>-1.890000</td>\n",
       "      <td>23.013513</td>\n",
       "      <td>10.395126</td>\n",
       "      <td>5.531450</td>\n",
       "      <td>7.297137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3768.848446</td>\n",
       "      <td>3771.262000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>150.072997</td>\n",
       "      <td>87.971200</td>\n",
       "      <td>41.688090</td>\n",
       "      <td>41.688090</td>\n",
       "      <td>27.825543</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>224.520935</td>\n",
       "      <td>127.943354</td>\n",
       "      <td>93.203717</td>\n",
       "      <td>107.992337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5502.000000  5502.000000  5502.000000  5502.000000  5502.000000   \n",
       "mean    433.139807   433.659229     5.490549     1.239549     6.606325   \n",
       "std     193.011382   193.161908     4.460679     2.737377     6.442301   \n",
       "min     135.068414   135.166000     1.000000     0.000000     0.000000   \n",
       "25%     357.140875   357.479000     4.000000     0.000000     4.000000   \n",
       "50%     419.150511   419.529000     5.000000     1.000000     6.000000   \n",
       "75%     473.198238   473.853750     6.000000     1.000000     8.000000   \n",
       "max    3768.848446  3771.262000    92.000000    47.000000   137.000000   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  5502.000000  5502.000000  5502.000000  5502.000000  5502.000000  ...   \n",
       "mean      1.157761     4.710287    30.687023    59.501636     6.665213  ...   \n",
       "std       2.390030     2.943638    13.690007    27.377821     4.703330  ...   \n",
       "min       0.000000     0.000000    10.000000    19.000000     1.000000  ...   \n",
       "25%       0.000000     3.000000    25.000000    49.000000     5.000000  ...   \n",
       "50%       1.000000     4.000000    30.000000    57.000000     6.000000  ...   \n",
       "75%       1.000000     6.000000    33.000000    65.000000     8.000000  ...   \n",
       "max      42.000000    58.000000   266.000000   527.000000    93.000000  ...   \n",
       "\n",
       "                33           34           35           36           37  \\\n",
       "count  5502.000000  5502.000000  5502.000000  5502.000000  5502.000000   \n",
       "mean     17.728743    10.809153     6.080916     6.080916     4.375903   \n",
       "std       7.816940     4.699178     2.492909     2.492909     1.793121   \n",
       "min       5.593478     3.306776     1.073575     1.073575     0.534404   \n",
       "25%      14.628668     8.872773     4.980925     4.980925     3.547447   \n",
       "50%      17.118975    10.462253     5.830326     5.830326     4.158435   \n",
       "75%      19.190916    11.794588     6.695303     6.695303     4.892010   \n",
       "max     150.072997    87.971200    41.688090    41.688090    27.825543   \n",
       "\n",
       "                38           39           40           41           42  \n",
       "count  5502.000000  5502.000000  5502.000000  5502.000000  5502.000000  \n",
       "mean     -2.530154    21.342164     9.604665     5.091744     6.744692  \n",
       "std       1.382712    11.135756     6.088213     4.193230     5.006745  \n",
       "min     -25.750000     5.593184     1.904405     0.727470     1.065169  \n",
       "25%      -2.900000    17.284118     7.501125     3.649813     5.016531  \n",
       "50%      -2.380000    20.429792     9.055056     4.616490     6.220281  \n",
       "75%      -1.890000    23.013513    10.395126     5.531450     7.297137  \n",
       "max       0.480000   224.520935   127.943354    93.203717   107.992337  \n",
       "\n",
       "[8 rows x 43 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcontinuous_train = pd.DataFrame(continuous_train)\n",
    "# Dataset basic descriptive statistics\n",
    "dfcontinuous_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01ee497a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2079</th>\n",
       "      <th>2080</th>\n",
       "      <th>2081</th>\n",
       "      <th>2082</th>\n",
       "      <th>2083</th>\n",
       "      <th>2084</th>\n",
       "      <th>2085</th>\n",
       "      <th>2086</th>\n",
       "      <th>2087</th>\n",
       "      <th>2088</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.024355</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.015994</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.036169</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>0.021810</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.060705</td>\n",
       "      <td>0.036714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398037</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.029989</td>\n",
       "      <td>0.088513</td>\n",
       "      <td>0.028353</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.019629</td>\n",
       "      <td>0.038895</td>\n",
       "      <td>0.096874</td>\n",
       "      <td>0.038350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.154162</td>\n",
       "      <td>0.169062</td>\n",
       "      <td>0.125464</td>\n",
       "      <td>0.155835</td>\n",
       "      <td>0.186727</td>\n",
       "      <td>0.162334</td>\n",
       "      <td>0.146077</td>\n",
       "      <td>0.123341</td>\n",
       "      <td>0.238810</td>\n",
       "      <td>0.188076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489538</td>\n",
       "      <td>0.188523</td>\n",
       "      <td>0.170573</td>\n",
       "      <td>0.284066</td>\n",
       "      <td>0.165995</td>\n",
       "      <td>0.105564</td>\n",
       "      <td>0.138735</td>\n",
       "      <td>0.193362</td>\n",
       "      <td>0.295813</td>\n",
       "      <td>0.192056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2089 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2            3            4     \\\n",
       "count  5502.000000  5502.000000  5502.000000  5502.000000  5502.000000   \n",
       "mean      0.024355     0.029444     0.015994     0.024900     0.036169   \n",
       "std       0.154162     0.169062     0.125464     0.155835     0.186727   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              5            6            7            8            9     ...  \\\n",
       "count  5502.000000  5502.000000  5502.000000  5502.000000  5502.000000  ...   \n",
       "mean      0.027081     0.021810     0.015449     0.060705     0.036714  ...   \n",
       "std       0.162334     0.146077     0.123341     0.238810     0.188076  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "              2079         2080         2081         2082         2083  \\\n",
       "count  5502.000000  5502.000000  5502.000000  5502.000000  5502.000000   \n",
       "mean      0.398037     0.036896     0.029989     0.088513     0.028353   \n",
       "std       0.489538     0.188523     0.170573     0.284066     0.165995   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              2084         2085         2086         2087         2088  \n",
       "count  5502.000000  5502.000000  5502.000000  5502.000000  5502.000000  \n",
       "mean      0.011269     0.019629     0.038895     0.096874     0.038350  \n",
       "std       0.105564     0.138735     0.193362     0.295813     0.192056  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 2089 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfbinary_train = pd.DataFrame(binary_train)\n",
    "# Dataset basic descriptive statistics\n",
    "dfbinary_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f810d4-cf31-42c2-897e-0313febc7aaf",
   "metadata": {},
   "source": [
    "### Step 2. Scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b663e18a-0654-411b-97e9-8a6a5389c545",
   "metadata": {},
   "source": [
    "#### 2.1 Finding the best scaler for continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14c4ef27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Model</th>\n",
       "      <th>RVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.446537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.438138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.437365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.431850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>RandomForestRegressor(n_estimators=10)</td>\n",
       "      <td>0.428528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run        Scaler                                   Model       RVE\n",
       "42   4  Normalizer()  RandomForestRegressor(n_estimators=10)  0.446537\n",
       "6    0  Normalizer()  RandomForestRegressor(n_estimators=10)  0.438138\n",
       "33   3  Normalizer()  RandomForestRegressor(n_estimators=10)  0.437365\n",
       "24   2  Normalizer()  RandomForestRegressor(n_estimators=10)  0.431850\n",
       "15   1  Normalizer()  RandomForestRegressor(n_estimators=10)  0.428528"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = range(5)\n",
    "scalers = [MinMaxScaler(), StandardScaler(), Normalizer()]\n",
    "models = [RandomForestRegressor(n_estimators=10), DecisionTreeRegressor(max_depth=5), LinearRegression()]\n",
    "results = []\n",
    "\n",
    "for run in runs:\n",
    "    for scaler in scalers:\n",
    "        for model in models:\n",
    "            preds = runner(scaler, model, continuous_train, y_train, continuous_test)\n",
    "            calculate_rve(y_test, preds, run, model, results)\n",
    "\n",
    "rve_table_scalers = pd.DataFrame(results)\n",
    "rve_table_scalers = rve_table_scalers.sort_values(by = 'RVE', ascending = False)\n",
    "rve_table_scalers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17159c25-0476-4a5d-8e8d-87075baa43f6",
   "metadata": {},
   "source": [
    "#### 2.2 Apply the selected scaler to continuos data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c566131",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "scaler.fit(continuous_train)\n",
    "continuous_train_s = pd.DataFrame(scaler.transform(continuous_train))\n",
    "continuous_test_s  = pd.DataFrame(scaler.transform(continuous_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88662dc-96ee-432b-982c-9c345283cca1",
   "metadata": {},
   "source": [
    "### Step 3. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2816a9b-7922-41db-8dfa-5e29b985bf44",
   "metadata": {},
   "source": [
    "#### 3.1 Identify the most important features for the continuous data and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d1d1fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>RVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.491552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.491552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.491552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.491552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.491552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Threshold       RVE\n",
       "0  1.000000e-07  0.491552\n",
       "1  1.000000e-06  0.491552\n",
       "2  1.000000e-05  0.491552\n",
       "3  1.000000e-04  0.491552\n",
       "4  1.000000e-03  0.491552"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_fsc = []\n",
    "rfr = RandomForestRegressor(random_state = 4)\n",
    "t_range = [0.0000001, 0.000001, 0.00001, 0.0001, 0.001]\n",
    "for t in t_range:\n",
    "    sel = SelectFromModel(estimator = rfr, threshold = t)\n",
    "    sel.fit(continuous_train_s, y_train)\n",
    "    continuous_train_s_fs = sel.transform(continuous_train_s)\n",
    "    continuous_test_s_fs = sel.transform(continuous_test_s)\n",
    "    rfr.fit(continuous_train_s_fs, y_train)\n",
    "    rfr_preds = rfr.predict(continuous_test_s_fs)\n",
    "    results_fsc.append({'Threshold': t, 'RVE': explained_variance_score(y_test, rfr_preds)})\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "results_fsc = pd.DataFrame(results_fsc)\n",
    "results_fsc = results_fsc.sort_values(by = \"RVE\", ascending = False)\n",
    "results_fsc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e01086ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_fsc.plot(x = 'Threshold', y = 'RVE', style = 'o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('RVE')\n",
    "plt.legend('', frameon = False)\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556982ed",
   "metadata": {},
   "source": [
    "No feture selection for this data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0075c597-5542-4fda-812d-27271b343f2d",
   "metadata": {},
   "source": [
    "#### 3.1 Identify the most important features for the binary data and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60219a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>RVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.642460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.641089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.641089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.640711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.615286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Threshold       RVE\n",
       "3  1.000000e-04  0.642460\n",
       "0  1.000000e-07  0.641089\n",
       "1  1.000000e-06  0.641089\n",
       "2  1.000000e-05  0.640711\n",
       "4  1.000000e-03  0.615286"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_fsb = []\n",
    "rfr = RandomForestRegressor(random_state = 4)\n",
    "t_range = [0.0000001, 0.000001, 0.00001, 0.0001, 0.001]\n",
    "for t in t_range:\n",
    "    sel = SelectFromModel(estimator = rfr, threshold = t)\n",
    "    sel.fit(binary_train, y_train)\n",
    "    binary_train_fs = sel.transform(binary_train)\n",
    "    binary_test_fs = sel.transform(binary_test)\n",
    "    rfr.fit(binary_train_fs, y_train)\n",
    "    rfr_preds = rfr.predict(binary_test_fs)\n",
    "    results_fsb.append({'Threshold': t, 'RVE': explained_variance_score(y_test, rfr_preds)})\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "results_fsb = pd.DataFrame(results_fsb)\n",
    "results_fsb = results_fsb.sort_values(by = \"RVE\", ascending = False)\n",
    "results_fsb[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ed450ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_fsb.plot(x = 'Threshold', y = 'RVE', style = 'o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('RVE')\n",
    "plt.legend('', frameon = False)\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e950a-f580-408e-aef4-ff27271c7e77",
   "metadata": {},
   "source": [
    "#### 3.2 Selected features - transforming binary data by keeping the \"best\" set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a384965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state = 4)\n",
    "N,M = binary_train.shape\n",
    "sel = SelectFromModel(estimator = rfr, threshold = 0.0001)\n",
    "sel.fit(binary_train, y_train)\n",
    "features = sel.get_support()\n",
    "Features_selected = np.arange(M)[features]\n",
    "binary_train_fs = sel.transform(binary_train)\n",
    "binary_test_fs = sel.transform(binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8aaee254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected:  1570 out of the initial 2089 (75.2 %)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features selected: \", len (Features_selected), \"out of the initial\", M, \"(%4.1f\"%(((len (Features_selected))/M)*100),\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a7075f-a7ed-4a75-b6b5-9833b48a67b6",
   "metadata": {},
   "source": [
    "### Step 5. Fitting and tuning the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f78e35-a72e-44bc-af30-1bd451a0dab3",
   "metadata": {},
   "source": [
    "#### 5.1 Testing models and hyperparameters for continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11aa5900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LinearRegression...\n",
      "Processing Ridge...\n",
      "Processing Lasso...\n",
      "Processing ElasticNet...\n",
      "Processing DecisionTreeRegressor...\n",
      "Processing KNeighborsRegressor...\n",
      "Processing SVR...\n",
      "Processing RandomForestRegressor...\n",
      "Processing AdaBoostRegressor...\n",
      "Processing GradientBoostingRegressor...\n",
      "Processing XGBRegressor...\n",
      "Processing MLPRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "elastic_net = ElasticNet()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "svm_regressor = SVR()\n",
    "random_forest = RandomForestRegressor()\n",
    "abr = AdaBoostRegressor()\n",
    "gradient_boosting = GradientBoostingRegressor()\n",
    "xgboost_regressor = XGBRegressor()\n",
    "nnr = MLPRegressor()\n",
    "\n",
    "# Define hyperparameter grids\n",
    "param_grid_linear_regression = {}\n",
    "param_grid_ridge = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_lasso = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_elastic_net = {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "param_grid_decision_tree = {'max_depth': [None, 10, 20, 30], 'min_samples_leaf': [1, 5, 10, 20]}\n",
    "param_knn = {'n_neighbors': [1, 5, 10, 20], 'weights': ['uniform', 'distance']}\n",
    "param_grid_svm = {'gamma': [1e-1, 1e-7, 'scale'], 'C': [1, 10, 100], 'epsilon': [0.001, 0.1, 0.3]}\n",
    "param_grid_random_forest = {'n_estimators': [10, 100], 'max_depth': [None, 30]}\n",
    "param_abr = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "param_grid_gradient_boosting = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}\n",
    "param_grid_xgboost = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, None]}\n",
    "param_grid_nnr= {'hidden_layer_sizes': [(100, 100)], 'solver': ['lbfgs', 'sgd', 'adam'], 'alpha': [0.0001, 0.01, 0.1, 1], 'max_iter': [2000]}\n",
    "\n",
    "results_cont = pd.DataFrame(columns=['Model', 'Best Parameters', 'Best Explained Variance', 'RVE on Test Set'])\n",
    "\n",
    "# Create a list of models and their respective parameter grids\n",
    "models = [\n",
    "    (linear_regression, param_grid_linear_regression),\n",
    "    (ridge, param_grid_ridge),\n",
    "    (lasso, param_grid_lasso),\n",
    "    (elastic_net, param_grid_elastic_net),\n",
    "    (decision_tree, param_grid_decision_tree),\n",
    "    (knn, param_knn),\n",
    "    (svm_regressor, param_grid_svm),\n",
    "    (random_forest, param_grid_random_forest),\n",
    "    (abr, param_abr),\n",
    "    (gradient_boosting, param_grid_gradient_boosting),\n",
    "    (xgboost_regressor, param_grid_xgboost),\n",
    "    (nnr, param_grid_nnr)\n",
    "]\n",
    "\n",
    "# Iterate over models and perform GridSearchCV\n",
    "for model, param_grid in models:\n",
    "    print(f\"Processing {model.__class__.__name__}...\")\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='explained_variance', n_jobs=-1)\n",
    "    grid_search.fit(continuous_train_s, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Use the best estimator for prediction\n",
    "    preds = best_model.predict(continuous_test_s)\n",
    "    \n",
    "    # Calculate RVE on the test set\n",
    "    rve = explained_variance_score(y_test, preds)\n",
    "    \n",
    "    # Append results to the DataFrame\n",
    "    results_cont = pd.concat([results_cont, pd.DataFrame({\n",
    "        'Model': [model.__class__.__name__],\n",
    "        'Best Parameters': [str(grid_search.best_params_)],\n",
    "        'Best Explained Variance': [grid_search.best_score_],\n",
    "        'RVE on Test Set': [rve]\n",
    "    })], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbddebf1-f6f1-4fd5-8234-11a3145ce6fa",
   "metadata": {},
   "source": [
    "#### 5.2 Testing models and hyperparameters for binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ed6c4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LinearRegression...\n",
      "Processing Ridge...\n",
      "Processing Lasso...\n",
      "Processing ElasticNet...\n",
      "Processing DecisionTreeRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing KNeighborsRegressor...\n",
      "Processing SVR...\n",
      "Processing RandomForestRegressor...\n",
      "Processing AdaBoostRegressor...\n",
      "Processing GradientBoostingRegressor...\n",
      "Processing XGBRegressor...\n",
      "Processing MLPRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonamoravcikova/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "elastic_net = ElasticNet()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "svm_regressor = SVR()\n",
    "random_forest = RandomForestRegressor()\n",
    "abr = AdaBoostRegressor()\n",
    "gradient_boosting = GradientBoostingRegressor()\n",
    "xgboost_regressor = XGBRegressor()\n",
    "nnr = MLPRegressor()\n",
    "\n",
    "# Define hyperparameter grids\n",
    "param_grid_linear_regression = {}\n",
    "param_grid_ridge = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_lasso = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_elastic_net = {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "param_grid_decision_tree = {'max_depth': [None, 10, 20, 30], 'min_samples_leaf': [1, 5, 10, 20]}\n",
    "param_knn = {'n_neighbors': [1, 5, 10, 20], 'weights': ['uniform', 'distance']}\n",
    "param_grid_svm = {'gamma': [1e-1, 1e-7, 'scale'], 'C': [1, 10, 100], 'epsilon': [0.001, 0.1, 0.3]}\n",
    "param_grid_random_forest = {'n_estimators': [10, 100], 'max_depth': [None, 30]}\n",
    "param_abr = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "param_grid_gradient_boosting = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}\n",
    "param_grid_xgboost = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, None]}\n",
    "param_grid_nnr= {'hidden_layer_sizes': [(100, 100)], 'solver': ['lbfgs', 'sgd', 'adam'], 'alpha': [0.0001, 0.01, 0.1, 1], 'max_iter': [2000]}\n",
    "\n",
    "results_bin = pd.DataFrame(columns=['Model', 'Best Parameters', 'Best Explained Variance', 'RVE on Test Set'])\n",
    "\n",
    "# Create a list of models and their respective parameter grids\n",
    "models = [\n",
    "    (linear_regression, param_grid_linear_regression),\n",
    "    (ridge, param_grid_ridge),\n",
    "    (lasso, param_grid_lasso),\n",
    "    (elastic_net, param_grid_elastic_net),\n",
    "    (decision_tree, param_grid_decision_tree),\n",
    "    (knn, param_knn),\n",
    "    (svm_regressor, param_grid_svm),\n",
    "    (random_forest, param_grid_random_forest),\n",
    "    (abr, param_abr),\n",
    "    (gradient_boosting, param_grid_gradient_boosting),\n",
    "    (xgboost_regressor, param_grid_xgboost),\n",
    "    (nnr, param_grid_nnr)\n",
    "]\n",
    "\n",
    "# Iterate over models and perform GridSearchCV\n",
    "for model, param_grid in models:\n",
    "    print(f\"Processing {model.__class__.__name__}...\")\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='explained_variance', n_jobs=-1)\n",
    "    grid_search.fit(binary_train_fs, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Use the best estimator for prediction\n",
    "    preds = best_model.predict(binary_test_fs)\n",
    "    \n",
    "    # Calculate RVE on the test set\n",
    "    rve = explained_variance_score(y_test, preds)\n",
    "    \n",
    "    # Append results to the DataFrame\n",
    "    results_bin = pd.concat([results_bin, pd.DataFrame({\n",
    "        'Model': [model.__class__.__name__],\n",
    "        'Best Parameters': [str(grid_search.best_params_)],\n",
    "        'Best Explained Variance': [grid_search.best_score_],\n",
    "        'RVE on Test Set': [rve]\n",
    "    })], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a50945-99fe-4b15-a3e9-73dfc562fafd",
   "metadata": {},
   "source": [
    "### Step 6. Assessing the quality of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ae112-ef19-4c79-ac04-4ab01f0022a2",
   "metadata": {},
   "source": [
    "#### 6.1 Continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "772ced43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Explained Variance</th>\n",
       "      <th>RVE on Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.440361</td>\n",
       "      <td>0.489888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}</td>\n",
       "      <td>0.423528</td>\n",
       "      <td>0.487076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.382853</td>\n",
       "      <td>0.432875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'distance'}</td>\n",
       "      <td>0.254983</td>\n",
       "      <td>0.339450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.176586</td>\n",
       "      <td>0.176827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.143091</td>\n",
       "      <td>0.156754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100}</td>\n",
       "      <td>0.122294</td>\n",
       "      <td>0.144169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 100, 'epsilon': 0.1, 'gamma': 'scale'}</td>\n",
       "      <td>0.123453</td>\n",
       "      <td>0.136910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.150585</td>\n",
       "      <td>0.082858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.027589</td>\n",
       "      <td>0.034678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "7       RandomForestRegressor   \n",
       "10               XGBRegressor   \n",
       "9   GradientBoostingRegressor   \n",
       "5         KNeighborsRegressor   \n",
       "4       DecisionTreeRegressor   \n",
       "0            LinearRegression   \n",
       "8           AdaBoostRegressor   \n",
       "6                         SVR   \n",
       "11               MLPRegressor   \n",
       "1                       Ridge   \n",
       "2                       Lasso   \n",
       "3                  ElasticNet   \n",
       "\n",
       "                                                                          Best Parameters  \\\n",
       "7                                                {'max_depth': None, 'n_estimators': 100}   \n",
       "10                         {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}   \n",
       "9                             {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}   \n",
       "5                                              {'n_neighbors': 10, 'weights': 'distance'}   \n",
       "4                                               {'max_depth': 10, 'min_samples_leaf': 20}   \n",
       "0                                                                                      {}   \n",
       "8                                             {'learning_rate': 0.1, 'n_estimators': 100}   \n",
       "6                                            {'C': 100, 'epsilon': 0.1, 'gamma': 'scale'}   \n",
       "11  {'alpha': 0.1, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'lbfgs'}   \n",
       "1                                                                          {'alpha': 0.1}   \n",
       "2                                                                          {'alpha': 0.1}   \n",
       "3                                                         {'alpha': 0.1, 'l1_ratio': 0.1}   \n",
       "\n",
       "    Best Explained Variance  RVE on Test Set  \n",
       "7                  0.440361         0.489888  \n",
       "10                 0.423528         0.487076  \n",
       "9                  0.382853         0.432875  \n",
       "5                  0.254983         0.339450  \n",
       "4                  0.176586         0.176827  \n",
       "0                  0.143091         0.156754  \n",
       "8                  0.122294         0.144169  \n",
       "6                  0.123453         0.136910  \n",
       "11                 0.150585         0.082858  \n",
       "1                  0.027589         0.034678  \n",
       "2                  0.000000         0.000000  \n",
       "3                  0.000000         0.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "# Sort the DataFrame based on RVE in descending order\n",
    "results_cont = results_cont.sort_values(by='RVE on Test Set', ascending=False)\n",
    "results_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12320743-d310-4013-b696-541f686b0d5a",
   "metadata": {},
   "source": [
    "#### 6.1 Binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d4e1d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Explained Variance</th>\n",
       "      <th>RVE on Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}</td>\n",
       "      <td>0.643491</td>\n",
       "      <td>0.682323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.607392</td>\n",
       "      <td>0.642450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}</td>\n",
       "      <td>0.610118</td>\n",
       "      <td>0.640389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'alpha': 1, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.602432</td>\n",
       "      <td>0.626300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.596528</td>\n",
       "      <td>0.623032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.555084</td>\n",
       "      <td>0.569976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.517687</td>\n",
       "      <td>0.555008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.390650</td>\n",
       "      <td>0.479761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.402028</td>\n",
       "      <td>0.459125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 50}</td>\n",
       "      <td>0.209235</td>\n",
       "      <td>0.202871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.115630</td>\n",
       "      <td>0.125381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "6                         SVR   \n",
       "7       RandomForestRegressor   \n",
       "10               XGBRegressor   \n",
       "11               MLPRegressor   \n",
       "5         KNeighborsRegressor   \n",
       "9   GradientBoostingRegressor   \n",
       "1                       Ridge   \n",
       "0            LinearRegression   \n",
       "4       DecisionTreeRegressor   \n",
       "8           AdaBoostRegressor   \n",
       "3                  ElasticNet   \n",
       "2                       Lasso   \n",
       "\n",
       "                                                                        Best Parameters  \\\n",
       "6                                          {'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}   \n",
       "7                                              {'max_depth': None, 'n_estimators': 100}   \n",
       "10                       {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200}   \n",
       "11  {'alpha': 1, 'hidden_layer_sizes': (100, 100), 'max_iter': 2000, 'solver': 'lbfgs'}   \n",
       "5                                             {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "9                           {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}   \n",
       "1                                                                       {'alpha': 10.0}   \n",
       "0                                                                                    {}   \n",
       "4                                              {'max_depth': 20, 'min_samples_leaf': 5}   \n",
       "8                                            {'learning_rate': 0.1, 'n_estimators': 50}   \n",
       "3                                                       {'alpha': 0.1, 'l1_ratio': 0.1}   \n",
       "2                                                                        {'alpha': 0.1}   \n",
       "\n",
       "    Best Explained Variance  RVE on Test Set  \n",
       "6                  0.643491         0.682323  \n",
       "7                  0.607392         0.642450  \n",
       "10                 0.610118         0.640389  \n",
       "11                 0.602432         0.626300  \n",
       "5                  0.596528         0.623032  \n",
       "9                  0.555084         0.569976  \n",
       "1                  0.517687         0.555008  \n",
       "0                  0.390650         0.479761  \n",
       "4                  0.402028         0.459125  \n",
       "8                  0.209235         0.202871  \n",
       "3                  0.115630         0.125381  \n",
       "2                  0.000000         0.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "# Sort the DataFrame based on RVE in descending order\n",
    "results_bin = results_bin.sort_values(by='RVE on Test Set', ascending=False)\n",
    "results_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f51811b-afd0-47b1-b86b-7dbe0d94fb11",
   "metadata": {},
   "source": [
    "### Step 7. Select best models of approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b53d0a",
   "metadata": {},
   "source": [
    "#### 7.1 Selecting the best models, fiting and predicting - stack predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5432b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models on separate features\n",
    "regressor = RandomForestRegressor(max_depth = None, n_estimators = 100)\n",
    "classifier = SVR(C = 1 , epsilon = 0.001 , gamma = 'scale')\n",
    "\n",
    "regressor.fit(continuous_train_s, y_train)\n",
    "classifier.fit(binary_train_fs, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "regressor_preds = regressor.predict(continuous_test_s)\n",
    "classifier_preds = classifier.predict(binary_test_fs)\n",
    "\n",
    "# Combine predictions for stacking\n",
    "stacking_input = np.column_stack((regressor_preds, classifier_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97c1cb",
   "metadata": {},
   "source": [
    "#### 7.2 Find the best stacking model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae0dcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "elastic_net = ElasticNet()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "svm_regressor = SVR()\n",
    "random_forest = RandomForestRegressor()\n",
    "abr = AdaBoostRegressor()\n",
    "gradient_boosting = GradientBoostingRegressor()\n",
    "xgboost_regressor = XGBRegressor()\n",
    "nnr = MLPRegressor()\n",
    "\n",
    "# Define hyperparameter grids\n",
    "param_grid_linear_regression = {}\n",
    "param_grid_ridge = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_lasso = {'alpha': [0.1, 1.0, 10.0]}\n",
    "param_grid_elastic_net = {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "param_grid_decision_tree = {'max_depth': [None, 10, 20, 30], 'min_samples_leaf': [1, 5, 10, 20]}\n",
    "param_knn = {'n_neighbors': [1, 5, 10, 20], 'weights': ['uniform', 'distance']}\n",
    "param_grid_svm = {'gamma': [1e-1, 1e-7, 'scale'], 'C': [1, 10, 100], 'epsilon': [0.001, 0.1, 0.3]}\n",
    "param_grid_random_forest = {'n_estimators': [10, 100], 'max_depth': [None, 30]}\n",
    "param_abr = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "param_grid_gradient_boosting = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}\n",
    "param_grid_xgboost = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, None]}\n",
    "param_grid_nnr= {'hidden_layer_sizes': [(50, 50), (100, 100)], 'solver': ['lbfgs', 'sgd', 'adam'], 'alpha': [0.0001, 0.01, 0.1, 1], 'max_iter': [5000]}\n",
    "\n",
    "results_final = pd.DataFrame(columns=['Model', 'Best Parameters', 'Best Explained Variance', 'RVE on Test Set'])\n",
    "\n",
    "# Create a list of models and their respective parameter grids\n",
    "final_estimators = [\n",
    "    (linear_regression, param_grid_linear_regression),\n",
    "    (ridge, param_grid_ridge),\n",
    "    (lasso, param_grid_lasso),\n",
    "    (elastic_net, param_grid_elastic_net),\n",
    "    (decision_tree, param_grid_decision_tree),\n",
    "    (knn, param_knn),\n",
    "    (svm_regressor, param_grid_svm),\n",
    "    (random_forest, param_grid_random_forest),\n",
    "    (abr, param_abr),\n",
    "    (gradient_boosting, param_grid_gradient_boosting),\n",
    "    (xgboost_regressor, param_grid_xgboost),\n",
    "    (nnr, param_grid_nnr)\n",
    "]\n",
    "\n",
    "# Create and evaluate stacking models with different final estimators\n",
    "for final_estimator_name, param_grid_final_estimator in final_estimators:\n",
    "    # Perform GridSearchCV to find the best hyperparameters for the final estimator\n",
    "    grid_search_final_estimator = GridSearchCV(\n",
    "        estimator=final_estimator_name,\n",
    "        param_grid=param_grid_final_estimator,\n",
    "        cv=5,\n",
    "        scoring='explained_variance',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search_final_estimator.fit(stacking_input, y_test)\n",
    "    best_final_estimator = grid_search_final_estimator.best_estimator_\n",
    "\n",
    "    # Train the final model on stacking_input and y_test\n",
    "    final_model = StackingRegressor(\n",
    "        estimators=[('regressor', regressor), ('classifier', classifier)],\n",
    "        final_estimator=best_final_estimator\n",
    "    )\n",
    "\n",
    "    final_model.fit(stacking_input, y_test)\n",
    "\n",
    "    # Make predictions using the final model\n",
    "    final_preds = final_model.predict(stacking_input)\n",
    "\n",
    "    # Calculate RVE for the final predictions\n",
    "    final_rve = explained_variance_score(y_test, final_preds)\n",
    "\n",
    "    # Append results to the DataFrame\n",
    "    results_final = pd.concat([results_final, pd.DataFrame({\n",
    "        'Model': [final_estimator_name.__class__.__name__],\n",
    "        'Best Parameters': [str(grid_search_final_estimator.best_params_)],\n",
    "        'Best Explained Variance': [grid_search_final_estimator.best_score_],\n",
    "        'RVE on Test Set': [final_rve]\n",
    "    })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f2649281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Explained Variance</th>\n",
       "      <th>RVE on Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'max_iter': 5000, 'solver': 'adam'}</td>\n",
       "      <td>6.956643e-01</td>\n",
       "      <td>0.811349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>6.919251e-01</td>\n",
       "      <td>0.747347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{}</td>\n",
       "      <td>6.919195e-01</td>\n",
       "      <td>0.746903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'uniform'}</td>\n",
       "      <td>6.881447e-01</td>\n",
       "      <td>0.740515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>6.865292e-01</td>\n",
       "      <td>0.726408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}</td>\n",
       "      <td>6.892403e-01</td>\n",
       "      <td>0.725820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100}</td>\n",
       "      <td>6.864321e-01</td>\n",
       "      <td>0.715251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 100, 'epsilon': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>6.958026e-01</td>\n",
       "      <td>0.710245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 20}</td>\n",
       "      <td>6.695568e-01</td>\n",
       "      <td>0.686815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>6.391257e-01</td>\n",
       "      <td>0.648038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1}</td>\n",
       "      <td>4.048263e-01</td>\n",
       "      <td>0.555676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>8.881784e-17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "11               MLPRegressor   \n",
       "1                       Ridge   \n",
       "0            LinearRegression   \n",
       "5         KNeighborsRegressor   \n",
       "10               XGBRegressor   \n",
       "9   GradientBoostingRegressor   \n",
       "8           AdaBoostRegressor   \n",
       "6                         SVR   \n",
       "4       DecisionTreeRegressor   \n",
       "7       RandomForestRegressor   \n",
       "3                  ElasticNet   \n",
       "2                       Lasso   \n",
       "\n",
       "                                                                        Best Parameters  \\\n",
       "11  {'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'max_iter': 5000, 'solver': 'adam'}   \n",
       "1                                                                        {'alpha': 0.1}   \n",
       "0                                                                                    {}   \n",
       "5                                             {'n_neighbors': 20, 'weights': 'uniform'}   \n",
       "10                          {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}   \n",
       "9                            {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}   \n",
       "8                                          {'learning_rate': 0.01, 'n_estimators': 100}   \n",
       "6                                              {'C': 100, 'epsilon': 0.1, 'gamma': 0.1}   \n",
       "4                                           {'max_depth': None, 'min_samples_leaf': 20}   \n",
       "7                                              {'max_depth': None, 'n_estimators': 100}   \n",
       "3                                                       {'alpha': 0.1, 'l1_ratio': 0.1}   \n",
       "2                                                                        {'alpha': 0.1}   \n",
       "\n",
       "    Best Explained Variance  RVE on Test Set  \n",
       "11             6.956643e-01         0.811349  \n",
       "1              6.919251e-01         0.747347  \n",
       "0              6.919195e-01         0.746903  \n",
       "5              6.881447e-01         0.740515  \n",
       "10             6.865292e-01         0.726408  \n",
       "9              6.892403e-01         0.725820  \n",
       "8              6.864321e-01         0.715251  \n",
       "6              6.958026e-01         0.710245  \n",
       "4              6.695568e-01         0.686815  \n",
       "7              6.391257e-01         0.648038  \n",
       "3              4.048263e-01         0.555676  \n",
       "2              8.881784e-17         0.000000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "# Sort the DataFrame based on RVE in descending order\n",
    "results_final = results_final.sort_values(by='RVE on Test Set', ascending=False)\n",
    "results_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1e15a-969b-49a1-a994-9abad8cdd1d7",
   "metadata": {},
   "source": [
    "#### 7.3 Compare results from approach 1 and approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9c9ac70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Explained Variance</th>\n",
       "      <th>RVE on Test Set</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Approach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'max_iter': 5000, 'solver': 'adam'}</td>\n",
       "      <td>0.695664</td>\n",
       "      <td>0.811349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.691925</td>\n",
       "      <td>0.747347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.691920</td>\n",
       "      <td>0.746903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'uniform'}</td>\n",
       "      <td>0.688145</td>\n",
       "      <td>0.740515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.686529</td>\n",
       "      <td>0.726408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}</td>\n",
       "      <td>0.689240</td>\n",
       "      <td>0.725820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100}</td>\n",
       "      <td>0.686432</td>\n",
       "      <td>0.715251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 100, 'epsilon': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.695803</td>\n",
       "      <td>0.710245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.669557</td>\n",
       "      <td>0.686815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}</td>\n",
       "      <td>0.644669</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>Without PCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  \\\n",
       "11               MLPRegressor   \n",
       "1                       Ridge   \n",
       "0            LinearRegression   \n",
       "5         KNeighborsRegressor   \n",
       "10               XGBRegressor   \n",
       "9   GradientBoostingRegressor   \n",
       "8           AdaBoostRegressor   \n",
       "6                         SVR   \n",
       "4       DecisionTreeRegressor   \n",
       "6                         SVR   \n",
       "\n",
       "                                                                        Best Parameters  \\\n",
       "11  {'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'max_iter': 5000, 'solver': 'adam'}   \n",
       "1                                                                        {'alpha': 0.1}   \n",
       "0                                                                                    {}   \n",
       "5                                             {'n_neighbors': 20, 'weights': 'uniform'}   \n",
       "10                          {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}   \n",
       "9                            {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}   \n",
       "8                                          {'learning_rate': 0.01, 'n_estimators': 100}   \n",
       "6                                              {'C': 100, 'epsilon': 0.1, 'gamma': 0.1}   \n",
       "4                                           {'max_depth': None, 'min_samples_leaf': 20}   \n",
       "6                                          {'C': 1, 'epsilon': 0.001, 'gamma': 'scale'}   \n",
       "\n",
       "    Best Explained Variance  RVE on Test Set      Dataset Approach  \n",
       "11                 0.695664         0.811349          NaN        2  \n",
       "1                  0.691925         0.747347          NaN        2  \n",
       "0                  0.691920         0.746903          NaN        2  \n",
       "5                  0.688145         0.740515          NaN        2  \n",
       "10                 0.686529         0.726408          NaN        2  \n",
       "9                  0.689240         0.725820          NaN        2  \n",
       "8                  0.686432         0.715251          NaN        2  \n",
       "6                  0.695803         0.710245          NaN        2  \n",
       "4                  0.669557         0.686815          NaN        2  \n",
       "6                  0.644669         0.681507  Without PCA        1  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results['Approach'] = '1'\n",
    "results_final['Approach'] = '2'\n",
    "\n",
    "# Combine the two DataFrames\n",
    "results = pd.concat([combined_results, results_final])\n",
    "\n",
    "# Sort the combined DataFrame based on RVE in descending order\n",
    "results = results.sort_values(by='RVE on Test Set', ascending=False)\n",
    "\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca77c26a-7928-44a9-8fdc-d1ff86f7b605",
   "metadata": {},
   "source": [
    "#### 7.4 Apply the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2734aff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;regressor&#x27;, RandomForestRegressor()),\n",
       "                              (&#x27;classifier&#x27;, SVR(C=1, epsilon=0.001))],\n",
       "                  final_estimator=MLPRegressor(alpha=0.01,\n",
       "                                               hidden_layer_sizes=(50, 50),\n",
       "                                               max_iter=5000))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;regressor&#x27;, RandomForestRegressor()),\n",
       "                              (&#x27;classifier&#x27;, SVR(C=1, epsilon=0.001))],\n",
       "                  final_estimator=MLPRegressor(alpha=0.01,\n",
       "                                               hidden_layer_sizes=(50, 50),\n",
       "                                               max_iter=5000))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>regressor</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>classifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=1, epsilon=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=5000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('regressor', RandomForestRegressor()),\n",
       "                              ('classifier', SVR(C=1, epsilon=0.001))],\n",
       "                  final_estimator=MLPRegressor(alpha=0.01,\n",
       "                                               hidden_layer_sizes=(50, 50),\n",
       "                                               max_iter=5000))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final model\n",
    "final_model = StackingRegressor(\n",
    "    estimators=[('regressor', regressor), ('classifier', classifier)],\n",
    "    final_estimator=MLPRegressor(alpha = 0.01, hidden_layer_sizes = (50, 50), max_iter = 5000, solver= 'adam')\n",
    ")\n",
    "\n",
    "# Train the final model on stacking_input and y_test\n",
    "final_model.fit(stacking_input, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaf412a-7f51-4778-8fe0-4c6857ea1f4d",
   "metadata": {},
   "source": [
    "### Step 8. Produce best estimators for y_ivs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fc045c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same transformation to X_ivs\n",
    "continuous_ivs = X_ivs[:, :43]\n",
    "binary_ivs = X_ivs[:, 43:]\n",
    "\n",
    "continuous_ivs_s  = pd.DataFrame(scaler.transform(continuous_ivs))\n",
    "binary_ivs_fs = sel.transform(binary_ivs)\n",
    "\n",
    "# Make predictions on the test set\n",
    "regressor_preds_ivs = regressor.predict(continuous_ivs_s)\n",
    "classifier_preds_ivs = classifier.predict(binary_ivs_fs)\n",
    "\n",
    "# Combine predictions for stacking on x_ivs\n",
    "stacking_input_ivs = np.column_stack((regressor_preds_ivs, classifier_preds_ivs))\n",
    "\n",
    "# Make predictions using the final model on x_ivs\n",
    "final_preds_ivs = final_model.predict(stacking_input_ivs)\n",
    "\n",
    "\n",
    "np.savetxt('14.txt', final_preds_ivs, fmt='%.3f')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
